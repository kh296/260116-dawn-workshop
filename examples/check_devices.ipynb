{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f8a87f6-2695-4206-9d2d-df04a7284f91",
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "import os\n",
    "import random\n",
    "import time\n",
    "\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72eed7c4-2fe9-4282-8119-9fc72065782c",
   "metadata": {},
   "source": [
    "An Intel GPU card may be made up of multiple stacks, also known as tiles.\n",
    "Stack visibility is controlled by the environment variable `ZE_FLAT_DEVICE_HIERARCHY`.\n",
    "If it is set to `\"FLAT\"` (default), each GPU stack is made visible as a separate device.\n",
    "If it is set to `\"COMPOSITE\"`, the GPU card is seen as a single device.\n",
    "\n",
    "In `torch`, the visibility of a device needs to be set before the device is initialised,\n",
    "and can't subsequently be changed.  If on a system with Intel GPUs, try running this notebook for the differnt visibility modes.\n",
    "\n",
    "**WARNING**: When running on a GPU, the function `torch_matrix_multiplication` terminates when it attempts multiplication of matrices that are sufficiently large to generate an out-of-memory error.  This gives an idea of the GPU memory available.  Recovery from the error can take a little while (usually seconds rather than minutes).  If you want to avoid this, you can set a limit on matrix size for all device types - not just for `\"cpu\"`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ac6a39c-7f1d-42c3-88c3-2c0928d48b28",
   "metadata": {},
   "outputs": [],
   "source": [
    "modes = [\"FLAT\", \"COMPOSITE\"]\n",
    "mode = modes[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2556a64-132f-45da-b199-766d7ecee233",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pytorch_check_devices(mode=\"FLAT\"):\n",
    "    \"\"\"\n",
    "    Check devices available on current system, for specified visibility mode.\n",
    "    \"\"\"\n",
    "    \n",
    "    os.environ[\"ZE_FLAT_DEVICE_HIERARCHY\"] = mode\n",
    "\n",
    "    # Define device types to be considered.\n",
    "    device_types = [\"cpu\", \"cuda\", \"mps\", \"xpu\", \"fictional_device\"]\n",
    "    \n",
    "    # Print information about available device types.\n",
    "    print(f\"{mode} mode - devices seen by torch:\")\n",
    "    for device_type in sorted(device_types):\n",
    "        # Determine number of devices of each type.\n",
    "        try:\n",
    "            device_module = importlib.import_module(f\"torch.{device_type}\")\n",
    "        except ModuleNotFoundError:\n",
    "            device_module = None\n",
    "        n_device = getattr(device_module, \"device_count\", lambda: 0)()\n",
    "        devices = [f\"{device_type}:{idx}\" for idx in range(n_device)]\n",
    "        print(f\"    {device_type}: {devices}\")\n",
    "    print()\n",
    "\n",
    "pytorch_check_devices(mode=mode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "896a48d0-a6db-40cd-a33a-3f73b848a270",
   "metadata": {},
   "outputs": [],
   "source": [
    "def torch_matrix_multiplication(mode=\"FLAT\"):\n",
    "    \"\"\"\n",
    "    Check time for multiplication of square matrices of different ranks,\n",
    "    using different device types, and specified visibility mode.\n",
    "    \"\"\"\n",
    "    os.environ[\"ZE_FLAT_DEVICE_HIERARCHY\"] = mode\n",
    "    # Define device types to be considered.\n",
    "    device_types = [\"cpu\", \"cuda\", \"mps\", \"xpu\", \"fictional_device\"]\n",
    "    # Number of times to attempt matrix multiplication.\n",
    "    n_attempt = 3\n",
    "    # Print information about available device types.\n",
    "    for device_type in device_types:\n",
    "        # Determine number of devices of each type.\n",
    "        try:\n",
    "            device_module = importlib.import_module(f\"torch.{device_type}\")\n",
    "        except ModuleNotFoundError:\n",
    "            device_module = None\n",
    "        if hasattr(device_module, \"is_available\") and device_module.is_available():\n",
    "            n_device = device_module.device_count()\n",
    "        else:\n",
    "            n_device = 0\n",
    "        print(f\"\\n{mode} mode - device type: {device_type}\")\n",
    "        print(f\"Number of devices: {n_device}\")\n",
    "        # Test matrix-multiplication time for all devices of current type,\n",
    "        # considering devices in random order.\n",
    "        indices = list(range(n_device))\n",
    "        random.shuffle(indices)\n",
    "        i_dim = 0\n",
    "        while n_device:\n",
    "            dim = 2**i_dim\n",
    "            i_dim += 1\n",
    "            i_attempt = 0\n",
    "            print()\n",
    "            while i_attempt < n_attempt:\n",
    "                i_attempt += 1\n",
    "                for i_device in indices:\n",
    "                    device_name = f\"{device_type}:{i_device}\"\n",
    "                    if dim > 1024 and \"cpu\" == device_type:\n",
    "                        n_device = 0\n",
    "                        i_attempt = n_attempt + 1\n",
    "                        break\n",
    "                    t0 = time.time()\n",
    "                    try:\n",
    "                        x=torch.randn((dim, dim), device=torch.device(device_name))\n",
    "                        y=torch.randn((dim, dim), device=torch.device(device_name))\n",
    "                        z=torch.matmul(x,y)\n",
    "                    except RuntimeError:\n",
    "                        n_device =0\n",
    "                    t1 = time.time()\n",
    "                    if n_device:\n",
    "                        print(f\"{device_name}: order = {dim}; \"\n",
    "                                f\"attempt ={i_attempt : 3d}; \"\n",
    "                                f\"time ={(t1 - t0) * 1.e6 : 8.1f} microseconds\")\n",
    "                    else:\n",
    "                        print(f\"{device_type}: order = {dim}; out of memory\")\n",
    "                        i_attempt = n_attempt + 1\n",
    "                        break\n",
    "\n",
    "torch_matrix_multiplication(mode=mode)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "diffusion-models",
   "language": "python",
   "name": "diffusion-models"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
